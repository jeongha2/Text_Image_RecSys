{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mxnet\n",
    "!pip install gluonnlp tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install soynlp\n",
    "!pip install emoji\n",
    "!pip install AdamP\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import cv2\n",
    "\n",
    "# 텍스트 모델 불러오기\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\", do_lower_case=False)\n",
    "\n",
    "config = BertConfig.from_pretrained('beomi/kcbert-base')\n",
    "config.num_labels = 6\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/kcbert-base\",\n",
    "                                                         config = config).to(cuda)\n",
    "\n",
    "#학습시켜 놓은 모델 설정\n",
    "file_path = \"/Model/kcbert_3\"\n",
    "model.load_state_dict(torch.load(file_path))\n",
    "model.to(cuda)\n",
    "\n",
    "\n",
    "def convert_input_data(sentences):\n",
    "    global tokenizer\n",
    "    \n",
    "    tokenized_texts = tokenizer.tokenize(sentences)\n",
    "    MAX_LEN = 128\n",
    "    input_ids = [[tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    attention_masks = []\n",
    "    \n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks\n",
    "\n",
    "def logits_to_softmax(logits):\n",
    "  odds = np.exp(logits)\n",
    "  total = odds.sum()\n",
    "  softmax = odds/total\n",
    "  return softmax\n",
    "\n",
    "def classify_sentence(new_sentence):\n",
    "  model.eval()\n",
    "\n",
    "  inputs, masks = convert_input_data(new_sentence)\n",
    "  b_input_ids = inputs.to(cuda)\n",
    "  b_input_mask = masks.to(cuda)\n",
    "\n",
    "  with torch.no_grad():     \n",
    "    outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()[0]\n",
    "\n",
    "  result = logits_to_softmax(logits)\n",
    "\n",
    "  emotion_dict = {0:\"angry\",1:\"disgust\",2:\"fear\",3:\"happy\",4:\"sad\",5:\"surprise\"}\n",
    "\n",
    "  for i in range(len(result)):\n",
    "    print(f\"{emotion_dict[i]} : {round(result[i]*100,3)}%\")\n",
    "  \n",
    "  return result\n",
    "\n",
    "new_sentence = \"아 개웃기다ㅋㅋ\"\n",
    "classify_sentence(new_sentence)\n",
    "\n",
    "# 이미지 모델 불러오기\n",
    "\n",
    "cascade_filename = './haarcascade_frontalface_alt.xml'\n",
    "cascade = cv2.CascadeClassifier(cascade_filename)\n",
    "\n",
    "img_model = tf.keras.models.load_model('/content/drive/MyDrive/비타민 컨퍼런스/Model/CNN_7.h5')\n",
    "\n",
    "# 사진 출력\n",
    "def imgDetector(img,cascade,model):\n",
    "    img = cv2.resize(img,dsize=None,fx=0.5,fy=0.5)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    results = cascade.detectMultiScale(gray,\n",
    "                                  scaleFactor = 1.2,\n",
    "                                  minNeighbors = 1,\n",
    "                                  minSize=(10,10)\n",
    "                                  )\n",
    "    max_area = 0\n",
    "    area = 0\n",
    "    \n",
    "    if len(results) >0:\n",
    "        for box in results:\n",
    "            x,y,w,h = box\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), thickness=1)\n",
    "            area = h*w\n",
    "\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                face = img[y:y+h,x:x+h]\n",
    "\n",
    "        output_face = cv2.resize(face,dsize=(48,48),fx=0.5,fy=0.5)\n",
    "        gray_output_face = cv2.cvtColor(output_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_array = image.img_to_array(gray_output_face)/255.0\n",
    "        face_resized = tf.reshape(img_array, (-1,48,48,1))\n",
    "        # face_resized\n",
    "        pred = model.predict(face_resized,steps=1)[0]\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    else:\n",
    "        output_img = cv2.resize(img,dsize=(48,48),fx=0.5,fy=0.5)\n",
    "        gray_output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)\n",
    "        plt.imshow(gray_output_img,cmap='gray')\n",
    "        return\n",
    "\n",
    "base_dir = './'\n",
    "img_dir = os.path.join(base_dir, 'images')\n",
    "all_img_fnames = os.listdir( img_dir )\n",
    "\n",
    "img_result = {}\n",
    "total_not_detected = 0\n",
    "\n",
    "for i in all_img_fnames : \n",
    "    try:\n",
    "      img_read = cv2.imread(img_dir + f'/{i}')\n",
    "      face_dict = imgDetector(img_read,cascade,img_model)\n",
    "\n",
    "      if face_dict is None:\n",
    "        total_not_detected += 1\n",
    "        print(f\"No face detected : {i}\")\n",
    "\n",
    "      img_result[i] = face_dict\n",
    "\n",
    "    except:\n",
    "      print(f\"Error image : {i}\")\n",
    "      pass\n",
    "\n",
    "img_result = pd.DataFrame(img_result)\n",
    "img_result = img_result.rename(index = {0:\"angry\",1:\"disgust\",2:\"fearful\",3:\"happy\",4:\"sad\",5:\"surprised\"} ) \n",
    "img_result = img_result.dropna(axis = 1 )\n",
    "\n",
    "img_result.to_csv(\"./result\",index = False)\n",
    "\n",
    "# Recommend\n",
    "\n",
    "img_result = pd.read_csv(\"./result\")\n",
    "\n",
    "def recommend_images(sentence) : \n",
    "    global img_result\n",
    "    res = classify_sentence(sentence)\n",
    "    img_result['sentence'] = res\n",
    "\n",
    "    def cos_sim(A, B):\n",
    "        return np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
    "\n",
    "    rec_image = {}\n",
    "\n",
    "    for i in img_result.columns[:-1] : \n",
    "      cos = cos_sim(img_result['sentence'] , img_result[i])\n",
    "      rec_image[i] = cos\n",
    "\n",
    "    path = './images'\n",
    "    n = 1\n",
    "    fig = plt.figure()\n",
    "    sorted_dict = sorted(rec_image.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "    rand_int = np.random.choice(30,3, replace=False)\n",
    "\n",
    "    choosed_pic = []\n",
    "\n",
    "    for i in rand_int:\n",
    "      choosed_pic.append(sorted_dict[i])\n",
    "\n",
    "    for i in choosed_pic : \n",
    "      filename = os.path.join(path,i[0])\n",
    "      img_array = img.imread(filename)\n",
    "      output_img = cv2.resize(img_array,dsize=(200,200),fx=0.5,fy=0.5)\n",
    "      ax = fig.add_subplot(1,3,n)\n",
    "      ax.imshow(output_img)\n",
    "      n += 1\n",
    "    \n",
    "    return\n",
    "\n",
    "sentence = \"진짜 개웃기다 실화임?\"\n",
    "recommend_images(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
